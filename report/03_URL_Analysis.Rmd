---
title: "URL Dataset"
author: "Bill"
date: "11/10/21"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
```

The next set of data we investigate comprises of two lists of URLs, the first lists benign URLs and the second lists phishing URLs. The data set underpinned a 2016 Canadian research paper "Detecting Malicious URLs Using Lexical Analysis", and was subsequently released by the University of New Brunswick.

Most of the code uses no special packages, but make sure you've got the `dplyr` package correctly loaded.

### 1. Getting and Formatting the Data

To get this data use the following instructions:

* Download the folder from https://www.unb.ca/cic/datasets/url-2016.html (it's not a monster set of data, the folder is 10's of MB).

* Change your working directory to the folder "URL" which lies **inside** the folder just downloaded. I moved the "URL" folder to my desktop and had therefore used `setwd("/Users/willnunn/Desktop/URL")`.

We can now read the two lists, add column names and add new column which labels whether the URL is benign or a phish.

```{r}
benign <- read.csv(file = "Benign_list_big_final.csv")
colnames(benign) <- c("URL")
benign["Phish"] = rep(0, nrow(benign))

phish <- read.csv(file = "phishing_dataset.csv")
colnames(phish) <- c("URL")
phish["Phish"] = rep(1, nrow(phish))
```

After this I bound the above dataframes into a single labeled dataframe, carried out a sanity check expecting an output of `0 1` and removed the redundant dataframes to keep the environment tidy.

```{r}
df <- rbind.data.frame(benign, phish)
df[nrow(benign):(nrow(benign)+1), 2]
rm(benign, phish)
```

We are ready to get on with the exploratory data analysis.

### 2. Comparison of URL Lengths

Since we've constructed a neat labeled dataframe we should probably look for ways to compare the two classes. The first port of call was to investigate how the lengths of the URLs varied between the two classes. I started by adding a `"Length"` column to `df` using `dplyr`'s extremely useful `mutate` function.

```{r}
df <- df %>% mutate(Length = nchar(URL))
head(df["Length"])
```

Seeing that all 6 of the head outputs were `83` was unsettling, my guess (after checking my code) was that the original URL csv files were already ordered by URL length. This guess was correct. We now produce a plot of the densities of the two classes.

```{r, fig.align = 'center'}
d0 <- density(df$Length[df$Phish == 0])
d1 <- density(df$Length[df$Phish == 1])

plot(d0, xlim = c(0, 300), col = "blue", main = "Density Plot",
     xlab = "URL Length")
lines(d1, col = "red")
legend(x = "topright", legend = c("Benign", "Phish"),
       col = c("blue", "red"), lwd = 1)
```
```{r, include=FALSE}
rm(d0, d1)
```

Two features of this plot stood really stood out to me.

* There is a much greater density of phishing URLs of length 20 to 80.

* There is a very distinctive bump in the density of the phishing URLs around length 200. This is completely absent from the density of the Benign URLs.

I wasn't too surprised by the first of these features- I suspect there is an advantage in having shorter phishing URLs as they are more likely to be trusted by careless users. As for the increased density around 200, that warranted more investigation. I checked out some of the phishing URLs which were around this length and found many were of the form http://appleid.apple.co.uk.cgi-bin. I suppose these were part of the same large scale phishing operation. Given more time I would want go on to try and determine whether these URLs were generated by the same algorithm.

### 3. Character Counts

The next idea was to compare the proportions of characters in the classes. We start by finding the character counts for the two classes. Note that I wrote the functions `transition_count()` and `combine_counts()` before starting work on section 3 and so I lazily re-hashed these functions to count the number of each character, see section 4 for the full code of these functions. The function `char_count()` is a very small modification of `transition_count()`

```{r, include=FALSE}
combine_counts <- function(df1, df2) {
  new_rows <- union(rownames(df1), rownames(df2))
  new_cols <- union(colnames(df1), colnames(df2))
  df <- data.frame(new_rows, new_cols) %>%
    table %>%
    as.data.frame.matrix()
  for(i in new_rows){
    for(j in new_cols){
      df[i,j] = max(na.exclude(df1[i, j]), 0) + 
        max(na.exclude(df2[i,j]), 0)
    }
  }
  rm(new_rows, new_cols)
  return(df)
}
```

```{r}
char_count <- function(string) {
  broken <- unlist(strsplit(string, ""))
  counts <- data.frame(x = broken[1:length(broken)]) %>% 
    table() %>% 
    as.matrix() %>%
    as.data.frame()
  rm(broken)
  return(counts)
}
```

To illustrate the action of `char_count()` we apply it to a test string.

```{r}
char_count("abbadgesfds")
```

We can then find the character counts for the two classes.

```{r}
seedf <- data.frame()
for(i in data.frame(df[which(df$Phish == 0), 1])){
  seedf <- combine_counts(seedf, char_count(i))
}
rm(i)
benign_char <- as.matrix(seedf)

seedf <- data.frame()
for(i in data.frame(df[which(df$Phish == 1), 1])){
  seedf <- combine_counts(seedf, char_count(i))
}
rm(i)
phish_char <- as.matrix(seedf)
rm(seedf)
```

We'll keep the lower case letters, upper case letters, numbers and some symbols.

```{r}
lows <- "qwertyuiopasdfghjklzxcvbnm"
v1 <- unlist(strsplit(lows, ""))
ups <- toupper(lows)
v2 <- unlist(strsplit(ups, ""))
numbs <- "1234567890"
v3 <- unlist(strsplit(numbs, ""))
syms <- "/.:%+=?"
v4 <- unlist(strsplit(syms, ""))
keeps <- c(v1, v2, v3, v4)
rm(lows, v1, ups, v2, numbs, v3, syms, v4)

benign_char <- benign_char[keeps, ]
phish_char <- phish_char[keeps, ]
```

The raw counts aren't particularly useful as the total number of phish is quite different from the total number of benign URLs. We therefore find the proportion of the total number of the characters each individual character occupies.

```{r}
ben_tot <- sum(benign_char)
phi_tot <- sum(phish_char)
benign_prop <- benign_char / ben_tot
phish_prop <- phish_char / phi_tot
rm(ben_tot, phi_tot)
```

We plot the proportions, I liked Olivers horizontal bars so I copied him.

```{r, fig.align='center'}
par(mfrow= c(1,2))
barplot(benign_prop, ylab="Character",
        xlab ="Proportion", main="Benign Character Proportion",
        names.arg = keeps, horiz = T, col="blue", yaxt='n')
barplot(phish_prop, ylab="Character",
        xlab="Proportion", main="Phish Character Proportion",
        names.arg = keeps, horiz = T, col="red", yaxt='n')
```

There appears to be a few characters which have quite different proportions between the two classes, lets find out which characters these are!

```{r}
ratio <- benign_prop/phish_prop
sort(ratio)
```

The characters at either ends of this sorted list should be investigated more fully. I'm particularly interested by the very large discrepancy in "+" and "%" but this could just be due to infrequent occurrence. Also the significant difference in the number of "/" is interesting, especially given forward slashes are certain to appear in every URL.

```{r}
benign_prop["+"]
benign_prop["%"]
```

We see that there's not much heft to the "+" discrepancy but the "%" discrepancy is certainly still intriguing.

### 4. Markov Transistion Counts

We will construct two matrices `benign_counts` and `phish_counts`, where the entry of `benign_counts` indexed by "a", "b" denotes the number of times letter sequence "ab" occurs in the list of benign URLs. I shall refer to such counts as the Markov transition counts. My first instinct was to make a massive dataframe where the first variable listed the letters of each URL and the second gave the letter which followed, and then apply the `table()` function to this dataframe. I then realised I could find the counts more neatly, by finding the counts for each URL individually and then combining these counts as I went along. Defining two functions helped me do this.


The first function `transition_counts()` takes a string as input and returns the Markov transition counts.

```{r}
transition_counts <- function(string) {
  broken <- unlist(strsplit(string, ""))
  counts <- data.frame(x = broken[1:length(broken)-1],
                       y = broken[2:length(broken)]) %>% 
    table() %>% 
    as.data.frame.matrix()
  rm(broken)
  return(counts)
}
```

To illustrate the action of `transition_counts()` we'll see how it acts on a couple of strings (I store the results for the illustration the second function).

```{r}
string1 <- "ababbbabccabb"
string2 <- "abdddbbaabdddbab"
df1 <- transition_counts(string1)
df2 <- transition_counts(string2)
df1
df2
```

The second function `combine_counts()` combines the outputs of `transition_counts()` into a single dataframe.

```{r}
combine_counts <- function(df1, df2) {
  new_rows <- union(rownames(df1), rownames(df2))
  new_cols <- union(colnames(df1), colnames(df2))
  df <- data.frame(new_rows, new_cols) %>%
    table %>%
    as.data.frame.matrix()
  for(i in new_rows){
    for(j in new_cols){
      df[i,j] = max(na.exclude(df1[i, j]), 0) + 
        max(na.exclude(df2[i,j]), 0)
    }
  }
  rm(new_rows, new_cols)
  return(df)
}
```

To illustrate the action of `combine_counts()` we apply it to the outputs of `transition_counts()` which we stored above as `df1` and `df2`.

```{r}
combine_counts(df1, df2)
```
```{r, include=FALSE}
rm(string1, string2, df1, df2)
```

Now we apply out functions to the data to construct the `benign_counts` and `phish_counts` matrices.

```{r}
seedf <- data.frame()
for(i in data.frame(df[which(df$Phish == 0), 1])){
  seedf <- combine_counts(seedf, transition_counts(i))
}
rm(i)

benign_counts <- seedf
rm(seedf)

seedf <- data.frame()
for(i in data.frame(df[which(df$Phish == 1), 1])){
  seedf <- combine_counts(seedf, transition_counts(i))
}
rm(i)

phish_counts <- seedf
rm(seedf)
```

We'll just keep the transitions to and from lower case letters, upper case letters, numbers and some symbols. Recall that this is the `keeps` variable from section 3.

```{r}
benign_counts_plot <- benign_counts[keeps, keeps]
phish_counts_plot <- phish_counts[keeps, keeps]
```

Now we can finally make some plot this hard earned data with a pair of heatmaps. The function `heatmap()` rearranges the columns and rows by default, and since we want the heatmaps to be easily comparable I fixed the order using `Rowv=NA` and `Colv=NA`.

```{r, fig.align = 'center'}
heatmap(as.matrix(benign_counts_plot),
        main = "Benign Markov Counts",
        labRow = F, labCol = F,
        Rowv = NA, Colv = NA)

heatmap(as.matrix(phish_counts_plot), 
        main = "Phish Markov Counts",
        labRow = F, labCol = F,
        Rowv = NA, Colv = NA)
```

I really didn't expect these heatmaps to look quite so distinct. The standout feature seems to be the central horizontal band which is much more pronounced for the Phish URLs. Perhaps a Markov classifier wouldn't be quite as useless for this data as I would have initially guessed. My skepticism does still remain however. The horizontal band could be caused by all phishing URLs from the same phishing operation, the http://appleid.apple.co.uk.cgi-bin
URLs for instance. These heatmaps do seem to suggest that the phishing URLs may have a greater entropy, this aligns with expectation given phishing URLs often try to impersonate a trusted URL by swapping in visually similar characters.

## 5. Lexical Analysis

It is worth noting here that a classifier which takes just the URL string as input is a very attractive prospect. The most effective methods for detecting malicious URLs usually involve analysis of the traffic and webpage content itself, but a classifier which takes just the URL would be much more computationally lightweight, and also accessing the potentially dangerous sites would no longer be required.

The paper "Detecting Malicious URLs Using Lexical Analysis" sought to construct a classifier which took the URL as the only input. Five components of the URL were used to derive the features: URI, domain, path, argument and file name. A set of lexical features (e.g. domain entropy, symbol counts, number of tokens, number of top level domains) were extracted, a task I didn't replicate given the time frame and my shoddy (for now!) string manipulation skills. Feature selection algorithms were applied, the data split into training and test sets and a selection of machine learning classifiers trained and tested. The Precision and Recall were both 0.99 for the random forest classifier. The data set of the extracted features is available and it could be a good set to test out some machine learning methods Adam kindly shared on Teams.
